# -*- coding: utf-8 -*-
"""DATA 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18cbBVZ-nb_7G3CxqliL08Hpwk22d7zZZ

https://www.kaggle.com/datasets/iamtanmayshukla/lung-cancer-data
"""

# Import Library
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

import warnings
warnings.filterwarnings("ignore")

"""# Dataset"""

# Load Dataset
df = pd.read_csv('/content/drive/MyDrive/SKRIPSI /Untitled folder/lung cancer survey.csv')
df.head()

"""#Exploratory Data Analysis"""

df.info()

df.describe()

df.isnull().sum()

# Membandingkan frekuensi Konsumsi Alkohol vs Kanker Paru-Paru
plt.figure(figsize=(8, 6))
sns.countplot(x='ALCOHOL CONSUMING', hue='LUNG_CANCER', data=df, palette='viridis')
plt.title('Konsumsi Alkohol vs Kanker Paru-Paru')
plt.xlabel('Konsumsi Alkohol (1: Tidak, 2: Ya)')
plt.ylabel('Frekuensi')
plt.legend(title='Kanker Paru-Paru', labels=['Tidak', 'Ya'])
plt.show()

"""# Preprocessing"""

le=LabelEncoder()
df["GENDER"]=le.fit_transform(df["GENDER"])
df["LUNG_CANCER"]=le.fit_transform(df["LUNG_CANCER"])
df.head()

# matrix korelasi
correlation_matrix = df.corr()
annot_kws = {"size": 5}
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", annot_kws=annot_kws)
plt.show()

correlation_matrix = df.corr()
correlation_with_target = correlation_matrix['LUNG_CANCER'].abs().sort_values(ascending=False)
print(correlation_with_target)

# Membuat feature X dan target Y
X = df[['YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE', 'CHRONIC DISEASE', 'FATIGUE ', 'ALLERGY ', 'WHEEZING', 'ALCOHOL CONSUMING', 'COUGHING', 'SWALLOWING DIFFICULTY','CHEST PAIN']]
y = df['LUNG_CANCER']

std = StandardScaler()
X_scaled = std.fit_transform(X)

#sebelum SMOTE
print("Class distribution before oversampling:")
print(y.value_counts())

plt.figure(figsize=(6, 6))
sns.set(font_scale=1.2)
sns.countplot(x=pd.Series(y))
plt.title('Sebelum SMOTE')
plt.show()

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_scaled,y)

plt.figure(figsize=(6, 6))
sns.set(font_scale=1.2)
sns.countplot(x=pd.Series(y_train_resampled))
plt.title('Setelah SMOTE')
plt.show()

"""#Model"""

# Splite data
X_train, X_test, y_train, y_test = train_test_split(X_train_resampled, y_train_resampled, test_size = 0.2,random_state=42)

print(len(X_train))
print(len(y_train))

from sklearn.neighbors import KNeighborsClassifier

# Inisialisasi model KNN
knn_model = KNeighborsClassifier(n_neighbors=5)

# Training model
knn_model.fit(X_train_resampled, y_train_resampled)

# Prediksi pada data uji
y_pred_knn = knn_model.predict(X_test)

# Evaluasi model
print(classification_report(y_test, y_pred_knn))
print(confusion_matrix(y_test,y_pred_knn))
print("Accuracy:",accuracy_score(y_test, y_pred_knn))

# Hyperparameter Tuning for KNN
param_grid = {
    'n_neighbors': range(1, 31),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_resampled, y_train_resampled)

best_k = grid_search.best_params_['n_neighbors']
best_accuracy = grid_search.best_score_

print(f'Nilai k terbaik dari GridSearchCV: {best_k}')
print(f'Accuracy untuk k terbaik: {best_accuracy*100}%')

for K in range(0, 10):
    K_value = K + 1
    neighbor = KNeighborsClassifier(n_neighbors= K_value)
    neighbor.fit(X_train, y_train)
    y_pred = neighbor.predict(X_test)
    print( "Accuracy is ", accuracy_score(y_test, y_pred)*100,"% for K-Value:",K_value)

# Evaluasi model dengan nilai k terbaik pada data pengujian
best_knn_model = grid_search.best_estimator_
y_pred = best_knn_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Akurasi pada data pengujian dengan k terbaik: {accuracy:.2f}')

# Menampilkan laporan klasifikasi
print(classification_report(y_test, y_pred))

print("\nConfusion Matrix (Test Set):")
print(confusion_matrix(y_test, y_pred))

from sklearn.svm import SVC

# Inisialisasi model SVM
svm_model = SVC(kernel='linear')

# Training model
svm_model.fit(X_train_resampled, y_train_resampled)

# Prediksi pada data uji
y_pred_svm = svm_model.predict(X_test)

# Evaluasi model
print(classification_report(y_test, y_pred_svm))
print(confusion_matrix(y_test, y_pred_svm))
print("Accuracy:", accuracy_score(y_test, y_pred_svm))

# Hyperparameter Tuning for SVM
param_grid_svm = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto', 0.1, 1]
}

grid_search_svm = GridSearchCV(estimator=SVC(), param_grid=param_grid_svm, cv=5, scoring='accuracy')
grid_search_svm.fit(X_train_resampled, y_train_resampled)

print("Best hyperparameters for SVM:", grid_search_svm.best_params_)
print("Best accuracy score for SVM:", grid_search_svm.best_score_)

best_svm_model = grid_search_svm.best_estimator_
y_pred_best_svm = best_svm_model.predict(X_test)

print(classification_report(y_test, y_pred_best_svm))
print(confusion_matrix(y_test, y_pred_best_svm))
print("Accuracy for tuned SVM:", accuracy_score(y_test, y_pred_best_svm))